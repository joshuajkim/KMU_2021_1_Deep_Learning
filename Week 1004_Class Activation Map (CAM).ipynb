{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Week 1004_Class Activation Map (CAM).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNP3DUMNbfEPb2lSM17f1cr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"87GC9yR9QCDR","executionInfo":{"status":"ok","timestamp":1627675314871,"user_tz":-540,"elapsed":17575,"user":{"displayName":"Joshua Jinseok Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVbcmSgzN3gDKiOEdERqfujlZoCjrufK-LwT3NTA=s64","userId":"10087421924635569822"}},"outputId":"bd4e7d80-5ae8-4678-f89a-24eb4b9fc9f1"},"source":["# My Google Drive Mount하기!\n","from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ePx8begcPf57","executionInfo":{"status":"ok","timestamp":1627675328584,"user_tz":-540,"elapsed":11919,"user":{"displayName":"Joshua Jinseok Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVbcmSgzN3gDKiOEdERqfujlZoCjrufK-LwT3NTA=s64","userId":"10087421924635569822"}},"outputId":"8e10e130-c4e1-4e5b-f76d-36cfa1dbfd94"},"source":["from tensorflow.keras.applications.vgg16 import VGG16\n","\n","model1 = VGG16(\n","    weights='imagenet'\n",")\n","model1.summary()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n","553467904/553467096 [==============================] - 4s 0us/step\n","Model: \"vgg16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 25088)             0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              102764544 \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","predictions (Dense)          (None, 1000)              4097000   \n","=================================================================\n","Total params: 138,357,544\n","Trainable params: 138,357,544\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TyTuAeWFPrjX","executionInfo":{"status":"ok","timestamp":1627675483826,"user_tz":-540,"elapsed":1752,"user":{"displayName":"Joshua Jinseok Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVbcmSgzN3gDKiOEdERqfujlZoCjrufK-LwT3NTA=s64","userId":"10087421924635569822"}},"outputId":"d3af9fd3-d080-48f8-ad47-56c4b337dfd9"},"source":["from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n","import numpy as np\n","import pandas as pd\n","\n","img_fpath = '/content/drive/MyDrive/03. Kookmin AI Big Data MBA/Semester 3_032021-062021/2. Deep Learning/Jupyter Notebook/data_Week 09/creative_commons_elephant.jpg'\n","\n","img = image.load_img(\n","    img_fpath,\n","    target_size=(224, 224)\n",")\n","\n","img_arr = image.img_to_array(img)\n","print('Original Shape:', img_arr.shape)\n","\n","img_arr = np.expand_dims(img_arr, axis=0)\n","print('New1 Shape:', img_arr.shape)\n","\n","img_arr = preprocess_input(img_arr) # preprocess_input: VGG16의 Input에 잘 적용되도록 적절히 변환해주는 것임!\n","print('New2 Shape:', img_arr.shape)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Original Shape: (224, 224, 3)\n","New1 Shape: (1, 224, 224, 3)\n","New2 Shape: (1, 224, 224, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IsQwmhgbPrg5","executionInfo":{"status":"ok","timestamp":1627675564795,"user_tz":-540,"elapsed":30478,"user":{"displayName":"Joshua Jinseok Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVbcmSgzN3gDKiOEdERqfujlZoCjrufK-LwT3NTA=s64","userId":"10087421924635569822"}},"outputId":"896bbdc4-ac8c-4a37-cce7-279e0f49ff4a"},"source":["img_pred = model1.predict(img_arr)\n","\n","print('Predicted:')\n","for each in decode_predictions(img_pred, top=5)[0]:\n","    print(each)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Predicted:\n","Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n","40960/35363 [==================================] - 0s 0us/step\n","('n02504458', 'African_elephant', 0.90942174)\n","('n01871265', 'tusker', 0.086182125)\n","('n02504013', 'Indian_elephant', 0.004354569)\n","('n02408429', 'water_buffalo', 3.9944192e-05)\n","('n02397096', 'warthog', 1.3171737e-06)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NcpED8PWPreE","executionInfo":{"status":"ok","timestamp":1627675637479,"user_tz":-540,"elapsed":322,"user":{"displayName":"Joshua Jinseok Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVbcmSgzN3gDKiOEdERqfujlZoCjrufK-LwT3NTA=s64","userId":"10087421924635569822"}},"outputId":"10d3c3cd-8f19-4071-8ec5-4fa8053917e0"},"source":["print(np.argmax(img_pred[0]))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["386\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SFjETAkHPrbO","executionInfo":{"status":"ok","timestamp":1627675838444,"user_tz":-540,"elapsed":328,"user":{"displayName":"Joshua Jinseok Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVbcmSgzN3gDKiOEdERqfujlZoCjrufK-LwT3NTA=s64","userId":"10087421924635569822"}},"outputId":"14141a1f-a72d-4385-da9e-bc9f0f5f14d0"},"source":["# 386번째 index의 확률을 찾아보자.\n","print(img_pred[0][386])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["0.90942174\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KuRNRUZHTCmJ"},"source":["* Grad-CAM 시작!\n","* Notice: Prof said, 아래의 코드는 **K.gradients** 문제 때문에 실행이 안되니, 아래의 User Defined Function을 그냥 쓰도록 하자!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":405},"id":"57__D24vPrYh","executionInfo":{"status":"error","timestamp":1621006787222,"user_tz":-540,"elapsed":911,"user":{"displayName":"Joshua Jinseok Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVbcmSgzN3gDKiOEdERqfujlZoCjrufK-LwT3NTA=s64","userId":"10087421924635569822"}},"outputId":"fb190ea4-7b89-41ad-fc93-6d7b6418b9cf"},"source":["from tensorflow.keras import backend as K\n","\n","AfricanElephant_output = model1.output[:, 386] # max softmax 값을 가졌던 output만을 가져온다.\n","\n","LastConvLayer = model1.get_layer('block5_conv3') # Pooling을 제외한, 가장 끝단에 있는 Convolutional Layer를 지정한다.\n","\n","gradient_arr = K.gradients(AfricanElephant_output, LastConvLayer.output)[0]\n","\n","gradientmean_arr = K.mean(gradient_arr, axis=(0, 1, 2))\n","\n","iterate = K.funciton([model1.input], [gradient_mean, LastConvLayer.output[0]])\n","\n","gradient_mean, ConvLayer_output = iterate([img_arr])\n","\n","for i in range(512): # 가장 끝단에 있는 Convolutional Layer의 Output Shape의 가장 마지막 값이 512임!\n","    ConvLayer_output[:, :, i] *= gradient_mean[i]\n","\n","heatmap_arr = np.mean(ConvLayer_output, axis=-1)\n","\n","print(heatmap_arr.shape)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-d4117aafdc8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mLastConvLayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'block5_conv3'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Pooling을 제외한, 가장 끝단에 있는 Convolutional Layer를 지정한다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mgradient_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAfricanElephant_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLastConvLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mgradientmean_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(loss, variables)\u001b[0m\n\u001b[1;32m   4101\u001b[0m   \"\"\"\n\u001b[1;32m   4102\u001b[0m   return gradients_module.gradients(\n\u001b[0;32m-> 4103\u001b[0;31m       loss, variables, colocate_gradients_with_ops=True)\n\u001b[0m\u001b[1;32m   4104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         unconnected_gradients)\n\u001b[0m\u001b[1;32m    173\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    490\u001b[0m   \u001b[0;34m\"\"\"Implementation of gradients().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m     raise RuntimeError(\"tf.gradients is not supported when eager execution \"\n\u001b[0m\u001b[1;32m    493\u001b[0m                        \"is enabled. Use tf.GradientTape instead.\")\n\u001b[1;32m    494\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msrc_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead."]}]},{"cell_type":"code","metadata":{"id":"tE-23eaHPrTO","executionInfo":{"status":"ok","timestamp":1627675905199,"user_tz":-540,"elapsed":350,"user":{"displayName":"Joshua Jinseok Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVbcmSgzN3gDKiOEdERqfujlZoCjrufK-LwT3NTA=s64","userId":"10087421924635569822"}}},"source":["import tensorflow as tf\n","def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n","    # First, we create a model that maps the input image to the activations\n","    # of the last conv layer as well as the output predictions\n","    grad_model = tf.keras.models.Model(\n","        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n","    )\n","\n","    # Then, we compute the gradient of the top predicted class for our input image\n","    # with respect to the activations of the last conv layer\n","    with tf.GradientTape() as tape:\n","        last_conv_layer_output, preds = grad_model(img_array)\n","        if pred_index is None:\n","            pred_index = tf.argmax(preds[0])\n","        class_channel = preds[:, pred_index]\n","\n","    # This is the gradient of the output neuron (top predicted or chosen)\n","    # with regard to the output feature map of the last conv layer\n","    grads = tape.gradient(class_channel, last_conv_layer_output)\n","\n","    # This is a vector where each entry is the mean intensity of the gradient\n","    # over a specific feature map channel\n","    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n","\n","    # We multiply each channel in the feature map array\n","    # by \"how important this channel is\" with regard to the top predicted class\n","    # then sum all the channels to obtain the heatmap class activation\n","    last_conv_layer_output = last_conv_layer_output[0]\n","    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n","    heatmap = tf.squeeze(heatmap)\n","\n","    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n","    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n","    return heatmap.numpy()"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lk41XyEWPrP7","executionInfo":{"status":"ok","timestamp":1627675926893,"user_tz":-540,"elapsed":3381,"user":{"displayName":"Joshua Jinseok Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVbcmSgzN3gDKiOEdERqfujlZoCjrufK-LwT3NTA=s64","userId":"10087421924635569822"}},"outputId":"f78d14ce-88a4-4186-a19e-8d26731c1267"},"source":["heatmap_arr = make_gradcam_heatmap(img_arr, model1, 'block5_conv3')\n","\n","print(heatmap_arr.shape)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["(14, 14)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"id":"YNknM1iqPrM6","executionInfo":{"status":"ok","timestamp":1627676055765,"user_tz":-540,"elapsed":338,"user":{"displayName":"Joshua Jinseok Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVbcmSgzN3gDKiOEdERqfujlZoCjrufK-LwT3NTA=s64","userId":"10087421924635569822"}},"outputId":"531ba585-b422-4e19-a420-fcf9f5460d63"},"source":["import matplotlib.pyplot as plt\n","\n","heatmap_arr = np.maximum(heatmap_arr, 0)\n","heatmap_arr = heatmap_arr / np.max(heatmap_arr)\n","plt.matshow(heatmap_arr)\n","plt.show()\n",";"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 288x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["''"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"eTnNUNYPWpIv"},"source":["* 위의 size가 14 X 14 밖에 안되므로, 좀 더 늘리기 위해, 아래의 openCV 코드를 사용한다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W4u2OmVyXSi1","executionInfo":{"status":"ok","timestamp":1623045289502,"user_tz":-540,"elapsed":4407,"user":{"displayName":"Joshua Jinseok Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVbcmSgzN3gDKiOEdERqfujlZoCjrufK-LwT3NTA=s64","userId":"10087421924635569822"}},"outputId":"a901669e-41ea-454d-8994-16fbd7593874"},"source":["! pip install opencv-python"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XfVqTKHvPrKP","executionInfo":{"status":"ok","timestamp":1623045296894,"user_tz":-540,"elapsed":1058,"user":{"displayName":"Joshua Jinseok Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVbcmSgzN3gDKiOEdERqfujlZoCjrufK-LwT3NTA=s64","userId":"10087421924635569822"}},"outputId":"67cce514-b219-4801-90b2-7d9ac3a86ce0"},"source":["import cv2\n","img_arr = cv2.imread(img_fpath)\n","\n","heatmap_arr = cv2.resize(heatmap_arr,\n","                         (img_arr.shape[1], img_arr.shape[0]))\n","\n","heatmap_arr = np.uint8(255 * heatmap_arr)\n","\n","heatmap_arr = cv2.applyColorMap(heatmap_arr, cv2.COLORMAP_JET)\n","\n","SuperImposed_img = heatmap_arr * 0.4 + img_arr\n","\n","cv2.imwrite('/content/drive/MyDrive/03. Kookmin AI Big Data MBA/Semester 3_032021-062021/2. Deep Learning/Jupyter Notebook/data_Week 09/elephant_cam.jpg', \n","            SuperImposed_img)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"UhE-o4dVXqG3"},"source":["* Now, 저장된 파일을 직접 열어서 확인해보자!"]}]}